{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## 2.1 텐서 다루기"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.1.1 리스트 포맷으로 pytorch tensor 만들기"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88712725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "------------------------\n",
      "tensor([[1, 2],\n",
      "        [3, 4]], device='cuda:0')\n",
      "------------------------\n",
      "tensor([[1., 2.],\n",
      "        [3., 4.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.tensor([[1, 2], [3, 4]]))\n",
    "print('------------------------')\n",
    "print(torch.tensor([[1, 2], [3, 4]], device=\"cuda:0\"))\n",
    "print('------------------------')\n",
    "print(torch.tensor([[1, 2], [3, 4]], dtype=torch.float64))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.1.2 pytorch tensor to numpy array"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13955c29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [3 4]]\n",
      "------------------------\n",
      "[[1 2]\n",
      " [3 4]]\n"
     ]
    }
   ],
   "source": [
    "temp = torch.tensor([[1, 2], [3, 4]])\n",
    "print(temp.numpy())\n",
    "print('------------------------')\n",
    "temp = torch.tensor([[1, 2], [3, 4]], device=\"cuda:0\")  #GPU가 없다면 오류가 발생하므로 주석 처리하였습니다.\n",
    "#temp = torch.tensor([[1,2],[3,4]], device=\"cpu:0\")\n",
    "print(temp.to(\"cpu\").numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.1.3 float type 텐서"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ceaaed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.) tensor(2.) tensor(7.)\n",
      "------------------------\n",
      "tensor([3., 4., 5.]) tensor([5., 6.])\n"
     ]
    }
   ],
   "source": [
    "temp = torch.FloatTensor([1, 2, 3, 4, 5, 6, 7])\n",
    "print(temp[0], temp[1], temp[-1])\n",
    "print('------------------------')\n",
    "print(temp[2:5], temp[4:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.1.4 텐서 연산"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35d9751c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "v = torch.tensor([1, 2, 3])\n",
    "w = torch.tensor([3, 4, 6])\n",
    "print(w - v)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "##  2.1.5 텐서 reshape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50d75b43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2])\n",
      "------------------------\n",
      "tensor([[1],\n",
      "        [2],\n",
      "        [3],\n",
      "        [4]])\n",
      "------------------------\n",
      "tensor([1, 2, 3, 4])\n",
      "------------------------\n",
      "tensor([[1, 2, 3, 4]])\n",
      "------------------------\n",
      "tensor([[1],\n",
      "        [2],\n",
      "        [3],\n",
      "        [4]])\n"
     ]
    }
   ],
   "source": [
    "temp = torch.tensor([\n",
    "    [1, 2], [3, 4]\n",
    "])\n",
    "\n",
    "print(temp.shape)\n",
    "print('------------------------')\n",
    "print(temp.view(4, 1))\n",
    "print('------------------------')\n",
    "print(temp.view(-1))\n",
    "print('------------------------')\n",
    "print(temp.view(1, -1))\n",
    "print('------------------------')\n",
    "print(temp.view(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2.2 파이토치 코드 맛보기"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44961535",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4fb364a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(r'../chap02/data/car_evaluation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63ea085b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "   price  maint doors persons lug_capacity safety output\n0  vhigh  vhigh     2       2        small    low  unacc\n1  vhigh  vhigh     2       2        small    med  unacc\n2  vhigh  vhigh     2       2        small   high  unacc\n3  vhigh  vhigh     2       2          med    low  unacc\n4  vhigh  vhigh     2       2          med    med  unacc",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>price</th>\n      <th>maint</th>\n      <th>doors</th>\n      <th>persons</th>\n      <th>lug_capacity</th>\n      <th>safety</th>\n      <th>output</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>vhigh</td>\n      <td>vhigh</td>\n      <td>2</td>\n      <td>2</td>\n      <td>small</td>\n      <td>low</td>\n      <td>unacc</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>vhigh</td>\n      <td>vhigh</td>\n      <td>2</td>\n      <td>2</td>\n      <td>small</td>\n      <td>med</td>\n      <td>unacc</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>vhigh</td>\n      <td>vhigh</td>\n      <td>2</td>\n      <td>2</td>\n      <td>small</td>\n      <td>high</td>\n      <td>unacc</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>vhigh</td>\n      <td>vhigh</td>\n      <td>2</td>\n      <td>2</td>\n      <td>med</td>\n      <td>low</td>\n      <td>unacc</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>vhigh</td>\n      <td>vhigh</td>\n      <td>2</td>\n      <td>2</td>\n      <td>med</td>\n      <td>med</td>\n      <td>unacc</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1854b091",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig_size = plt.rcParams[\"figure.figsize\"]\n",
    "# fig_size[0] = 8\n",
    "# fig_size[1] = 6\n",
    "# plt.rcParams[\"figure.figsize\"] = fig_size\n",
    "# dataset.output.value_counts().plot(kind='pie', autopct='%0.05f%%', colors=['lightblue', 'lightgreen', 'orange', 'pink'],\n",
    "#                                    explode=(0.05, 0.05, 0.05, 0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "73c82b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = ['price', 'maint', 'doors', 'persons', 'lug_capacity', 'safety']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "281fc4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "for category in categorical_columns:\n",
    "    dataset[category] = dataset[category].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c6b735e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([[3, 3, 0, 0, 2, 1],\n       [3, 3, 0, 0, 2, 2],\n       [3, 3, 0, 0, 2, 0],\n       [3, 3, 0, 0, 1, 1],\n       [3, 3, 0, 0, 1, 2],\n       [3, 3, 0, 0, 1, 0],\n       [3, 3, 0, 0, 0, 1],\n       [3, 3, 0, 0, 0, 2],\n       [3, 3, 0, 0, 0, 0],\n       [3, 3, 0, 1, 2, 1]], dtype=int8)"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "pd.DataFrame.cat.code.values : 데이터의 종류에 정수로 표현\n",
    "'''\n",
    "\n",
    "price = dataset['price'].cat.codes.values\n",
    "maint = dataset['maint'].cat.codes.values\n",
    "doors = dataset['doors'].cat.codes.values\n",
    "persons = dataset['persons'].cat.codes.values\n",
    "lug_capacity = dataset['lug_capacity'].cat.codes.values\n",
    "safety = dataset['safety'].cat.codes.values\n",
    "\n",
    "categorical_data = np.stack([price, maint, doors, persons, lug_capacity, safety], 1)\n",
    "categorical_data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "11ea6d73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[3, 3, 0, 0, 2, 1],\n        [3, 3, 0, 0, 2, 2],\n        [3, 3, 0, 0, 2, 0],\n        [3, 3, 0, 0, 1, 1],\n        [3, 3, 0, 0, 1, 2],\n        [3, 3, 0, 0, 1, 0],\n        [3, 3, 0, 0, 0, 1],\n        [3, 3, 0, 0, 0, 2],\n        [3, 3, 0, 0, 0, 0],\n        [3, 3, 0, 1, 2, 1]])"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "데이터 프레임을 파이토치 텐서로 바꿈\n",
    "torch.tensor(pd.Dataframe, dtype = torch.int64)\n",
    "'''\n",
    "\n",
    "categorical_data = torch.tensor(categorical_data, dtype=torch.int64)\n",
    "categorical_data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e765bcab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1728, 6])\n",
      "torch.Size([6912])\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "pd.get_dummies : object형의 데이터들 기계학습을 위해서 데이터를 수치화 시킨다.\n",
    "\n",
    "'''\n",
    "\n",
    "outputs = pd.get_dummies(dataset.output)\n",
    "outputs = outputs.values\n",
    "outputs = torch.tensor(outputs).flatten()\n",
    "\n",
    "print(categorical_data.shape)\n",
    "print(outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "828e0711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column 의 종류\n",
      "['price', 'maint', 'doors', 'persons', 'lug_capacity', 'safety']\n",
      "각 컬럼안에는 있는 데이터\n",
      "[Index(['high', 'low', 'med', 'vhigh'], dtype='object'), Index(['high', 'low', 'med', 'vhigh'], dtype='object'), Index(['2', '3', '4', '5more'], dtype='object'), Index(['2', '4', 'more'], dtype='object'), Index(['big', 'med', 'small'], dtype='object'), Index(['high', 'low', 'med'], dtype='object')]\n",
      "각 칼럼 안에 있는 데이터의 종류 갯수\n",
      "[4, 4, 4, 3, 3, 3]\n",
      "각 컬럼 안의 데이터 종류의 수, 그리고 그것을 2로 나눈 몫\n",
      "[(4, 2), (4, 2), (4, 2), (3, 2), (3, 2), (3, 2)]\n"
     ]
    }
   ],
   "source": [
    "print(\"column 의 종류\")\n",
    "print(categorical_columns)\n",
    "\n",
    "print(\"각 컬럼안에는 있는 데이터\")\n",
    "print([dataset[column].cat.categories for column in categorical_columns])\n",
    "\n",
    "print(\"각 칼럼 안에 있는 데이터의 종류 갯수\")\n",
    "categorical_column_sizes = [len(dataset[column].cat.categories) for column in categorical_columns]\n",
    "print(categorical_column_sizes)\n",
    "\n",
    "'''\n",
    "a//b 연산자 : a를 b로 나누었을 때 몫\n",
    "'''\n",
    "print(\"각 컬럼 안의 데이터 종류의 수, 그리고 그것을 2로 나눈 몫\")\n",
    "categorical_embedding_sizes = [(col_size, min(50, (col_size + 1) // 2)) for col_size in categorical_column_sizes]\n",
    "print(categorical_embedding_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "de38aa0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 총 데이터 수\n",
    "total_records = 1728\n",
    "\n",
    "# 테스트 데이터 수\n",
    "test_records = int(total_records * .2)\n",
    "\n",
    "# train data\n",
    "categorical_train_data = categorical_data[:total_records - test_records]\n",
    "\n",
    "# test data\n",
    "categorical_test_data = categorical_data[total_records - test_records:total_records]\n",
    "\n",
    "# output 혹은 타깃\n",
    "train_outputs = outputs[:total_records - test_records]\n",
    "test_outputs = outputs[total_records - test_records:total_records]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "46eb162b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1383\n",
      "1383\n",
      "345\n",
      "345\n"
     ]
    }
   ],
   "source": [
    "print(len(categorical_train_data))\n",
    "print(len(train_outputs))\n",
    "print(len(categorical_test_data))\n",
    "print(len(test_outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2eaa67ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, embedding_size, output_size, layers, p=0.4):\n",
    "\n",
    "        '''\n",
    "\n",
    "        :param embedding_size: 임베딩 사이즈\n",
    "        :param output_size:\n",
    "        :param layers:\n",
    "        :param p: 드롭 아웃 비율\n",
    "        '''\n",
    "\n",
    "        super().__init__()\n",
    "        '''\n",
    "        nn.ModuleList: 신경망의 모듈들의 리스트 index접근 가능\n",
    "        nn.Embedding: embedding 층\n",
    "        Embedding이란 말은 자연어 처리분야에서 매우 많이 등장하는 단어로 이산적, 범주형인 변수를 sparse한 one hot 인코딩 대신 연속적인 값을 가지는 벡터로 표현한는 방법\n",
    "        '''\n",
    "        self.all_embeddings = nn.ModuleList([nn.Embedding(ni, nf) for ni, nf in embedding_size])\n",
    "        self.embedding_dropout = nn.Dropout(p)\n",
    "\n",
    "        all_layers = []\n",
    "        num_categorical_cols = sum((nf for ni, nf in embedding_size))\n",
    "        input_size = num_categorical_cols\n",
    "\n",
    "        # 신경망 생성\n",
    "        for i in layers:\n",
    "            all_layers.append(nn.Linear(input_size, i))\n",
    "            all_layers.append(nn.ReLU(inplace=True))\n",
    "            all_layers.append(nn.BatchNorm1d(i))\n",
    "            all_layers.append(nn.Dropout(p))\n",
    "            # 각 층의 아웃풋의 크기는 다음 층의 인풋 사이즈\n",
    "            input_size = i\n",
    "\n",
    "        # 마지막 층은 regression 모델에서니까 linear 층\n",
    "        all_layers.append(nn.Linear(layers[-1], output_size))\n",
    "        self.layers = nn.Sequential(*all_layers)\n",
    "\n",
    "    def forward(self, x_categorical):\n",
    "        embeddings = []\n",
    "        for i, e in enumerate(self.all_embeddings):\n",
    "            embeddings.append(e(x_categorical[:, i]))\n",
    "        x = torch.cat(embeddings, 1)\n",
    "        x = self.embedding_dropout(x)\n",
    "        x = self.layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4909ff0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(\n",
      "  (all_embeddings): ModuleList(\n",
      "    (0-2): 3 x Embedding(4, 2)\n",
      "    (3-5): 3 x Embedding(3, 2)\n",
      "  )\n",
      "  (embedding_dropout): Dropout(p=0.4, inplace=False)\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=12, out_features=200, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Dropout(p=0.4, inplace=False)\n",
      "    (4): Linear(in_features=200, out_features=100, bias=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (7): Dropout(p=0.4, inplace=False)\n",
      "    (8): Linear(in_features=100, out_features=50, bias=True)\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (11): Dropout(p=0.4, inplace=False)\n",
      "    (12): Linear(in_features=50, out_features=4, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = Model(categorical_embedding_sizes, 4, [200, 100, 50], p=0.4)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "301d59a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "nn.CrossEntropyLoss() : classification에서 주로쓰이는 softmax함수를 이용할 때 쓰는 loss function\n",
    "'''\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3d5c313f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "56492e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:   1 loss: 1.60023487\n",
      "epoch:  26 loss: 1.38107908\n",
      "epoch:  51 loss: 1.30147707\n",
      "epoch:  76 loss: 1.19144297\n",
      "epoch: 101 loss: 1.08119500\n",
      "epoch: 126 loss: 0.93182111\n",
      "epoch: 151 loss: 0.81806785\n",
      "epoch: 176 loss: 0.75787783\n",
      "epoch: 201 loss: 0.69142503\n",
      "epoch: 226 loss: 0.65746498\n",
      "epoch: 251 loss: 0.63912427\n",
      "epoch: 276 loss: 0.62003350\n",
      "epoch: 301 loss: 0.60014272\n",
      "epoch: 326 loss: 0.58700377\n",
      "epoch: 351 loss: 0.59449834\n",
      "epoch: 376 loss: 0.58636332\n",
      "epoch: 401 loss: 0.57903302\n",
      "epoch: 426 loss: 0.56916434\n",
      "epoch: 451 loss: 0.56781286\n",
      "epoch: 476 loss: 0.55858994\n",
      "epoch: 500 loss: 0.5627627373\n"
     ]
    }
   ],
   "source": [
    "epochs = 500\n",
    "aggregated_losses = []\n",
    "train_outputs = train_outputs.to(device=device, dtype=torch.int64)\n",
    "for i in range(epochs):\n",
    "    i += 1\n",
    "    '''\n",
    "    RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)\n",
    "    머신러닝이 같은 디바이스에 있어야한다.\n",
    "\n",
    "    .cuda()로 gpu에 실행 가능하도록 하자\n",
    "    '''\n",
    "    y_pred = model(categorical_train_data).cuda()\n",
    "    single_loss = loss_function(y_pred, train_outputs)\n",
    "    aggregated_losses.append(single_loss)\n",
    "\n",
    "    if i % 25 == 1:\n",
    "        print(f'epoch: {i:3} loss: {single_loss.item():10.8f}')\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    single_loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(f'epoch: {i:3} loss: {single_loss.item():10.10f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fd2f1035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.55101478\n"
     ]
    }
   ],
   "source": [
    "test_outputs = test_outputs.to(device=device, dtype=torch.int64)\n",
    "'''\n",
    "이와 같이 no_grad() with statement에 포함시키게 되면 Pytorch는 autograd engine을 꺼버린다. 이 말은 더 이상 자동으로 gradient를 트래킹하지 않는다는 말이 된다.\n",
    "그러면 이런 의문이 들 수 있다. loss.backward()를 통해 backpropagation을 진행하지 않는다면 뭐 gradient를 게산하든지 말든지 큰 상관이 없는 것이 아닌가?\n",
    "\n",
    "맞는 말이다. torch.no_grad()의 주된 목적은 autograd를 끔으로써 메모리 사용량을 줄이고 연산 속도를 높히기 위함이다. 사실상 어짜피 안쓸 gradient인데 inference시에 굳이 계산할 필요가 없지 않은가?\n",
    "\n",
    "그래서 일반적으로 inference를 진행할 때는 torch.no_grad() with statement로 감싼다는 사실을 알면 된다.\n",
    "\n",
    "\n",
    "'''\n",
    "with torch.no_grad():\n",
    "    y_val = model(categorical_test_data).cuda()\n",
    "    loss = loss_function(y_val, test_outputs)\n",
    "print(f'Loss: {loss:.8f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6735f451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.4394,  1.3458, -2.8184, -2.7824],\n",
      "        [ 2.1844,  1.2613, -2.6424, -2.5761],\n",
      "        [ 2.6043,  1.6695, -3.1607, -3.0733],\n",
      "        [ 3.2251,  1.7176, -4.0744, -4.0000],\n",
      "        [ 2.4732,  1.2452, -3.0336, -3.1327]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(y_val[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5acf59f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "y_val = np.argmax(y_val.cpu(), axis=1)\n",
    "print(y_val[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a7e16502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[258   1]\n",
      " [ 80   6]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      1.00      0.86       259\n",
      "           1       0.86      0.07      0.13        86\n",
      "\n",
      "    accuracy                           0.77       345\n",
      "   macro avg       0.81      0.53      0.50       345\n",
      "weighted avg       0.79      0.77      0.68       345\n",
      "\n",
      "0.7652173913043478\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "print(confusion_matrix(test_outputs.cpu(), y_val))\n",
    "print(classification_report(test_outputs.cpu(), y_val))\n",
    "print(accuracy_score(test_outputs.cpu(), y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23a4969",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
